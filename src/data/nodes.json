[{"id": "etUj8mX6", "name": "Map visualizations", "labels": [], "text_md": "Map visualizations allow to:\n- Identify outliers in the spatial distribution of individual variables\n- Identify and highlight spatial correlations across multiple datasets.  \n- Identify and highlight spatial patterns of inequality at the subnational level (e.g., across districts, municipalities, and communities)\n\n", "links": ["3c7dZcB6"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 1}, {"id": "Z12lJnJp", "name": "Why do we write", "labels": [], "text_md": "We write to \n- **remember** and **organize** ideas\n- **understand** and to **learn**\n- **communicate** insights\n\n", "links": ["pS33XHDA"], "quotes": ["7DxSGUo6"], "sources": ["RnpNCnXf"], "n_links": 1}, {"id": "UXewQVNc", "name": "Reading and note-taking", "labels": [], "text_md": "- Reading and thinking are the main task. \n- The goal is to understand and come up with new ideas. \n- The notes are just the tangible outcome.\n\n\"The ability to express understanding in one's own words is a fundamental competency\", the same as the ability \"to distinguish the important bits of a text from the less important ones.\" (Ahrens, 2017, p. 54). \n\n", "links": ["pS33XHDA", "ZyufNNxO"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 2}, {"id": "3cbc3DFd", "name": "Confirmation bias", "labels": [], "text_md": "The very moment we decide on a hypothesis, our brains automatically go into search mode, scanning our surroundings for supporting data, (p. 79).\n\nCharles Darwin... forced himself to write down (and therefore elaborate on) the arguments that were the most critical of his theories. (p. 80). \n\n", "links": ["pS33XHDA"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 1}, {"id": "ZyufNNxO", "name": "Smart note-taking", "labels": [], "text_md": "According to Ahrens (2017), smart note taking requires:\n- Reading a text with questions in mind and try to relate it to other possible approaches\n- Spotting the limitations of a particular approach\n- Seeing what is *not* mentioned\n- Interpreting particular information within the bigger frame or argument of the text\n- Thinking hard about how the main ideas of the text connect with other ideas from different contexts:  *\"Notes are only as valuable as the ... reference networks they are embedded in.\"* (Ahrens, 2017, p. 108).\n\n", "links": ["FlUbxxop", "UXewQVNc"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 2}, {"id": "f6AE5k9M", "name": "Types of notes", "labels": [], "text_md": "1. **Fleeting notes**: Sever to capture \"raw\" ideas we come across. They are stored in one place for later processing.  They are only useful if reviewed and turned into proper notes within a day or so.\n2. **Literature notes**: Capture bibliographic details and brief description of sources.\n3. **Permanent notes**: Serve to develop ideas based on fleeting notes and literature notes.  Written in precise, clear, and brief full sentences. They can be understood even outside the context they were taken from.\n4. **Project notes**: Are only relevant to one particular project and can be discarded or archived after the project is finished\n\nTypical mistakes:\n- Treat every note as if it belongs to the \"permanent\" category\n- Collect notes only related to specific projects\n- Just collecting unprocessed fleeting notes\n\n", "links": ["o2aK159Q"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 1}, {"id": "o2aK159Q", "name": "Slip box", "labels": [], "text_md": "- The slipbox is a simple external system to organize one's thought, ideas, and collected facts.\n- To be effective, it has to be embedded in one's overarching workflow (daily routine)\n- Video of Prof. Niklas Luhmann: https://www.youtube.com/watch?v=qRSCKSPMuDc&feature=youtu.be&t=37m30s\n\n", "links": ["f6AE5k9M", "pS33XHDA"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 2}, {"id": "pS33XHDA", "name": "Knowledge management systems", "labels": [], "text_md": "- We need to compensate for the limitations of our brains by relying on external structures ('scafolding') to capture ideas and supports our thinking process.\n- Knowledge management systems help keep track of ever-increasing volume of information and relieve brain capacity to focus on what is important\n\n\n", "links": ["6bvsiUUz", "o2aK159Q", "3cbc3DFd", "Z12lJnJp", "UXewQVNc"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 5}, {"id": "d700Xe9w", "name": "Innovation is not a linear process", "labels": [], "text_md": "- The quest for innovation requires to constantly iterate between different tasks\n- The search for meaningful connections is a crucial part of any innovation processes (p. 114).\n- Any attempt to squeeze a non-linear process into a linear order only leads to problems and frustrations\n\n", "links": ["onHn6c4S", "nBYBmeNa"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 2}, {"id": "onHn6c4S", "name": "Iterative abstraction / re-specification", "labels": [], "text_md": "- Innovation requires to combine and re-combine ideas, liberating them from their original context by means of an iterative process of abstraction and re-specification. (Ahrens, 2017, p. 123).\n- Abstraction from concrete situations and re-specification allows to apply ideas from one practical context into another.\n\n", "links": ["5WJqHcE5", "d700Xe9w"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 2}, {"id": "QZ4e6WSS", "name": "Organization of data innovation", "labels": [], "text_md": "Success in data innovation depends to a large extent on the adequate organization of workflows for the practical implementation of new sources, technologies and methodologies. \n\nIt requires **breaking down the amorphous task of \"data innovation\" into  separable tasks**, which can be completed within reasonable time, and which are clearly connected to the delivery of specific, tangible outputs, and finally to the achievement of well-defined outcomes.\n\n", "links": ["QJsx3KmY", "oTbmWlt2", "nBYBmeNa"], "quotes": [], "sources": [], "n_links": 3}, {"id": "6bvsiUUz", "name": "Importance of an overarching workflow", "labels": [], "text_md": "- It is crucial to maintain a \"holistic perspective\" so everything that needs to be taken care of is in one place and can be processed in a standardized way\n- Having a simple, overarching and streamlined workflow in place helps to stay in control by focusing on the important things and being able to pick up tasks quickly where they are left off.\n\n\n", "links": ["nDxqu3EV", "eac4gaf6", "pS33XHDA", "nBYBmeNa"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 4}, {"id": "nDxqu3EV", "name": "Lessons from the shipping container", "labels": [], "text_md": "Ahrens (2017) explains how the initial attempts to introduce the use of the shipping container --a very simple solution--failed as long as ship owners failed to change their infrastructure and routines and to recognize that what mattered was the entire transport chain, from packaging of goods at the point of production to their delivery at the final destination.\n\n> It wasn\u2019t just another way of shipping goods. It was a whole new way of doing business. \n>(Ahrens, 2017, p. 40) \n\nSimilarly, simple innovations in statistical production can only be mainstreamed if they are accompanied by necessary changes and adaptations along the whole data value chain.\n\nFor example... (?)\n\n", "links": ["6bvsiUUz", "OkCaKf6I"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 2}, {"id": "OkCaKf6I", "name": "SDMX is the shipping container of official statistics", "labels": [], "text_md": "Paraphrasing https://trello.com/c/RnpNCnXf, \"\\[SDMX\\] is the shipping container of the \\[official statistics\\] world.  Instead of having different \\[mechanisms for the exchange of\\] different \\[datasets\\], everything goes into the same \\[multi-dimensional schema\\] and is standardized into the same format. (...) Everything is streamlined towards one thing only: \\[statistical data\\] that can be \\[easily exchanged with, and utilized by, users\\].\n\n", "links": ["nDxqu3EV"], "quotes": [], "sources": [], "n_links": 1}, {"id": "nBYBmeNa", "name": "Innovation: Plans vs structured workflows", "labels": [], "text_md": "- **Innovation requires flexibility**. Detailed plans often impose too much structure for open-ended research or innovation projects that require flexibility.  \n- **Innovation cannot be predetermined**: Initial ideas are necessarily vague and change when we put them into practice.\n- Accidental encounters make up the majority of what we learn\n- The challenge is to have **overarching workflows** that allow for new ideas and insights to be generated, tested, adapted and mainstreamed\n\n", "links": ["6bvsiUUz", "XkfA6AFU", "uhh1kRu3", "d700Xe9w", "QZ4e6WSS"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 5}, {"id": "uhh1kRu3", "name": "Innovation starts with what you have", "labels": [], "text_md": "- Innovation projects should start with what you *have*, not with \"an unfounded idea\" about what the data, technology and methods that plan acquire might provide.\n\n> Nobody ever starts from scratch\n\n", "links": ["CHr0Qnj2", "nBYBmeNa"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 2}, {"id": "CHr0Qnj2", "name": "Prioritize already available data and technology resources", "labels": [], "text_md": "Data innovation projects should prioritize and maximize the use of data sources and tools that are already under the control of the NSO and other members of the National Statistical System.\n\n", "links": ["uhh1kRu3"], "quotes": [], "sources": [], "n_links": 1}, {"id": "JExDAHlM", "name": "Simplicity is paramount", "labels": [], "text_md": "- Big transformations start with simple ideas.  What matters is how well these simple ideas fit in the overall workflows of a system or organization.\n- To avoid undesired side effects, it is important to focus on small units of work.\n\n\n", "links": ["3c7dZcB6", "vLPsC8l0", "eac4gaf6"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 3}, {"id": "XkfA6AFU", "name": "Exergonic vs endergonic workflows", "labels": [], "text_md": "Ahrens (2017) explains that workflows can be characterized as either \"exergonic\" (requiring constant addition of energy to keep them going) or \"endergonic\" (once triggered, they continue by themselves and even release energy).\n\nGood (endergonic) workflows turn into **virtuous cycles** where the experience of becoming better at what we do motivates us to take on the next task (Ahrens, 2017, p.53). \n\nSuch workflows need to include a **learning system** based on actionable **feedback loops**.\n\n", "links": ["nBYBmeNa"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 1}, {"id": "eac4gaf6", "name": "Why workflows become complicated", "labels": [], "text_md": "- Workflows become clogged over time as we try to apply a variety of new approaches and techniques, each promising to make something easier or better, but which combined have the opposite effects.\n- When new techniques are used without regard to the overarching workflow, \"nothing really fits together\", every little step suddenly becomes its own project, and it becomes very difficult to get things done.\n\n", "links": ["JExDAHlM", "6bvsiUUz"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 2}, {"id": "FlUbxxop", "name": "Be flexible - don't cling to a fixed idea", "labels": [], "text_md": "- Don't cling to an idea if another, more promising gains momentum\n- Follow your interest and always take the path that promises the most insight\n- The more you become interested in something, the more likely it is that you will generate insights from reading, taking notes, and writing about it\n\n", "links": ["ZyufNNxO"], "quotes": ["qh8vQ4LG"], "sources": ["RnpNCnXf"], "n_links": 1}, {"id": "1j2ClWxr", "name": "Understanding the how and the why", "labels": [], "text_md": "Only after we understand why and how new technologies and methods work, are we able to tweak them for our own needs.\n \n", "links": ["zGHMrgZh", "DLdh6sOz", "U3iX23IM"], "quotes": ["dEE3HyCw"], "sources": ["RnpNCnXf"], "n_links": 3}, {"id": "DLdh6sOz", "name": "Nothing is more practical than a good theory", "labels": [], "text_md": "Facts need to \"hang together on a latticework of theory\" in order to provide  insights that can be used to systematically solve real-world problems.\n\n", "links": ["1j2ClWxr"], "quotes": [], "sources": ["RnpNCnXf"], "n_links": 1}, {"id": "QGyxiutK", "name": "Key principles of data innovation projects", "labels": [], "text_md": "- Country ownership\n- Sustainability\n- Long-term relevance\n\n", "links": ["3jLAEhY0", "zGHMrgZh", "1P7GAwhy", "n3KkkMdF", "U3iX23IM", "CNiPnq0T", "wFd1FvbC"], "quotes": [], "sources": [], "n_links": 7}, {"id": "38O0h16q", "name": "Project champions", "labels": [], "text_md": "To be successful, data innovation projects need to identify champions willing to put their names behind them, who can mobilize resources and institutional support, as well as facilitate collaboration across different organizations.\n\nNational champions are especially crucial to help broker collaboration with key government agencies and partners. \n\n", "links": ["2j4pK36q", "38O0h16q"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 2}, {"id": "U3iX23IM", "name": "National ownership of data innovation projects", "labels": [], "text_md": "National ownership of data innovation projects requires local staff to have the ability and confidence to make the right choices regarding sources, technology and methods in real situations.\n\nCapacity development projects try to make learning easier for NSO staff by prearranging information, sorting it into modules, categories and themes, However, they achieve the opposite if they take away the opportunity to build meaningful connections to their needs and context.  \n\n", "links": ["QJsx3KmY", "1j2ClWxr", "zGHMrgZh", "wFd1FvbC", "oTbmWlt2", "QGyxiutK"], "quotes": ["dEE3HyCw"], "sources": [], "n_links": 6}, {"id": "wFd1FvbC", "name": "Ensuring national ownership of data innovation projects", "labels": [], "text_md": "**Risk**: \nExternal partners may be perceived by local teams as exerting too much ownership over the process\n\n**Mitigation**: \n- A specific entity within each country (usually the NSO) should be identified and recognized as the **owner** of every data innovation project. \n- This entity should be responsible to ensure the quality of outputs and should be willing to commit staff and invest resources in the project. \n- The main **focal point** for every country project should be within that entity, and all inquiries should be referred to that focal point first. \n- The first publication of all results should be done by the country, and publications by external partners should make reference to national publications\n\n\n\n", "links": ["3c7dZcB6", "3jLAEhY0", "U3iX23IM", "QGyxiutK"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 4}, {"id": "CNiPnq0T", "name": "Long-term relevance of data innovation projects", "labels": [], "text_md": "**Risk:**\nProject outputs and the data sources, methods and technologies used to generate them can become quickly outdated, due to rapid social, economic, environmental or technological changes.\n\n**Mitigation**:\n\n- Setup a continuous maintenance programme to keep IT infrastructure and systems up to date (e.g., software updates)\n- Update and release new results as new data inputs become available\n\n", "links": ["1k64R7UM", "P43SdKCs", "jwQ8qCBg", "zGHMrgZh", "oTbmWlt2", "QGyxiutK"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 6}, {"id": "3jLAEhY0", "name": "Importance of funding from national governments", "labels": [], "text_md": "Over the long term, building institutional capacity requires government funding.\n\nData innovation projects need to secure financial resources at the country level:\n\n- specific budget allocations\n- grants from external donors\n- shared resources from existing projects\n\n", "links": ["wFd1FvbC", "QGyxiutK"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 2}, {"id": "J7uVnj8B", "name": "Data privacy issues", "labels": [], "text_md": "Individual-records collected from surveys, censuses, administrative sources, and telecommunication providers, etc. are highly sensitive.  \n\nData innovation projects that use any of these sources need to have data privacy and security protocols in place when linking records from different data sources through common identifiers of individuals, households, businesses or geographies. \n\nThis is fundamental to avoid any reputation damage and ensure that organization that owns the project is trusted by all stakeholders, thus being able to keep the project running in the long term.\n\n", "links": ["9h1AmchL"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 1}, {"id": "hp8Foh4V", "name": "Capacity bottlenecks in data innovation projects", "labels": [], "text_md": "Common capacity bottlenecks in data innovation projects include:\n \n- Shortage of **facilities or equipment**\n- Gaps in technical **skills**\n- Lack of **staff time**\n- **Data quality** issues\n- Shortage of modern **software** tools\n\n\n", "links": ["Vk1c3Bjw", "Vmp2TR2i", "ptDLJoDD", "yHy01yYb", "VG23wXyp"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 5}, {"id": "ptDLJoDD", "name": "Facilities and equipment requirements", "labels": [], "text_md": "Data innovation projects require adequate IT infrastructure (e.g. server capacity for computing and data storage, personal computers, as well as broadband internet connectivity) and physical facilities to conduct planning and training workshops, on-site collaboration sessions, etc.\n\n", "links": ["hp8Foh4V"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 1}, {"id": "zGHMrgZh", "name": "Capacity building and sustainability", "labels": [], "text_md": "One of the main objectives of capacity building is to enable local staff to become technically **self-reliant** and to gain **confidence** and a strong sense of **ownership**.\n\nLocal staff should be able to understand and to explain to others not only the final outputs, but all aspects of the process, from beginning to end.\n\nCountry officers need to be able to replicate and update the outputs on a regular basis by their own means.\n\n", "links": ["1j2ClWxr", "HZvkseXI", "d3ru9pGK", "U3iX23IM", "CNiPnq0T", "ilCtHTAx", "QRWAHOzF", "QGyxiutK"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 8}, {"id": "d3ru9pGK", "name": "Building data engineering skills in NSOs", "labels": [], "text_md": "The ability of NSOs to transform source data into valuable statistics is increasingly dependent on its data infrastructure and \"data engineering\" skills.\n\nStatisticians need to develop foundational data engineering skills in order to be able to mainstream new data sources, methods and technologies into regular statistical production programmes.\n\nStatisticians are rarely given analysis-ready data that can be directly used in statistical estimation and compilation.  One of the main challenges in official statistics is \"to maintain statistical production pipelines\". \n\nPractical data innovation projects in official statistics require the ability to extract, organize and manipulate raw, unstructured source data, and to transform it into \"clean\" datasets that can be processed and analyzed using by standard software programmes and methodologies.\n\n", "links": ["oTbmWlt2", "zGHMrgZh"], "quotes": [], "sources": ["4z5iFWrh"], "n_links": 2}, {"id": "Cp7Quz8B", "name": "Capacity building in data engineering", "labels": [], "text_md": "Most capacity building in data innovation projects tends to focus on \"high-level\" skills such as artificial-intelligence, geoprocessing, or sophisticated estimation methodologies.   \n\nHowever, training workshops in data innovation usually neglect foundational data engineering skills, such as design of table schemas and practical implementation of data pipelines. \n\nAlthough not every statistician needs to become an expert in data engineering, NSOs need to have sufficient in-house data engineering skills to address critical real-life challenges in mainstreaming their data innovation projects into their regular official statistics production processes.\n\n", "links": ["Vmp2TR2i"], "quotes": [], "sources": ["4z5iFWrh"], "n_links": 1}, {"id": "4RDMe98t", "name": "Technical experts", "labels": [], "text_md": "Data innovation projects need to identify and bring on board technical experts who are deeply knowledgeable of the data inputs, technologies, and methods being pursued, and with ample practical experience in their implementation in the field.\n\n", "links": ["2j4pK36q"], "quotes": ["dEE3HyCw"], "sources": ["UCi2QXBJ"], "n_links": 1}, {"id": "Vmp2TR2i", "name": "Data engineering curriculum for official statisticians", "labels": [], "text_md": "Data innovation training curriculum for official statisticians should develop technical skills on the following topics:\n\n- **Data management** \n    - Transcoding and record-linking methods\n    - Statistical disclosure control methods\n    - Data warehousing / ETL pipelines\n- **Programming and coding**\n    - Python and/or R\n    - SQL\n- **GIS**\n    - Feature extraction from EO imagery\n    - Map visualizatoins\n- **Statistical / econometric estimation methods**\n    - Population-density estimation methods\n    - Small-area estimation methods\n    - Crop-yield estimation methods\n    - Household consumption estimation methods\n    - Poverty maps\n\n", "links": ["QJsx3KmY", "Cp7Quz8B", "hp8Foh4V", "P43SdKCs", "JiEdFdtg", "ilCtHTAx", "lEHhU8Ma", "Iaba3RcP"], "quotes": [], "sources": [], "n_links": 8}, {"id": "5W8MgJOp", "name": "Data Partitioning", "labels": [], "text_md": "**Data Partitioning** - breaking up data into independent, self-contained chunks, instead of storing in a single table or file.\n\nIt is \"a practice that enables more efficient querying and data backfilling\" (Chang, 2018b)\n\n", "links": ["FOPuLnHI"], "quotes": [], "sources": ["oIarYHfE"], "n_links": 1}, {"id": "Iaba3RcP", "name": "Key role of data warehouses", "labels": [], "text_md": "- \"A data warehouse is a place where raw data is transformed and stored in query-able forms\"\n- \"Data warehouses are both the engine and the fuels that enable higher level analytics\"\n- \"Without...foundational warehouses, every activity related to data science becomes either too expensive or not scalable\"\n\n", "links": ["Vmp2TR2i", "6OomPFuc"], "quotes": [], "sources": ["4z5iFWrh"], "n_links": 2}, {"id": "UHxZBMU2", "name": "Data Modelling", "labels": [], "text_md": "**Data Modeling** is \"a design process where one carefully defines table schemas and data relations to capture business metrics and dimensions\". (Chang, 2018b)\n\nData modelling is about optimizing data structures for analytic purposes.  It often involves sacrificing data normalization (i.e., accepting more data redundancy and more complex ETL pipelines to maintain) in order to facilitate data queries from tables where metrics and dimensions are already pre-joined.\n\n", "links": ["lEHhU8Ma", "6OomPFuc"], "quotes": [], "sources": ["oIarYHfE"], "n_links": 2}, {"id": "6OomPFuc", "name": "Star schema", "labels": [], "text_md": "Data warehouses generally implement a simple **star schema**, which consists of normalized fact and dimension tables that can be easily used to build denormalized tables for analytic purposes.\n\nA star schema design helps balance between ETL maintainability and ease of analytics.\n\n*Fact tables* - Contain the business metrics of interest\n*Dimension tables* - Contain slowly changing attributes (often organized in a hierarchical structure) that can be joined with the fact tables\n\n", "links": ["3BmAWMzw", "Iaba3RcP", "UHxZBMU2"], "quotes": [], "sources": ["oIarYHfE"], "n_links": 3}, {"id": "oTbmWlt2", "name": "Mainstreaming data innovation projects", "labels": [], "text_md": "It is crucial to ensure that the objectives and scope of national data innovation projects fit with the priorities of National Strategies for the Development of Statistics, with the regular work programme of NSOs and with the overall institutional setting of the National Statistical system.\n\nFor instance, there has to be a clear link between project outputs and SDG reporting platforms and VNR processes to ensure sustained demand from policy makers and other key stakeholders.\n\n", "links": ["5u1sLb2p", "d3ru9pGK", "n3KkkMdF", "U3iX23IM", "CNiPnq0T", "QZ4e6WSS"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 6}, {"id": "n3KkkMdF", "name": "Mainstreaming projects:  sustainability", "labels": [], "text_md": "When data innovation projects are viewed only as ad hoc activities, it is very difficult to secure long-term resources.   To be sustainable, data innovation projects need to be aligned with over-arching strategic plans and be embedded within the organization's existing multi-year programme of activities. This includes ensuring that the project activities are funded through regular budget sources and that they are adequately staffed over the long term. \n\n\n\n", "links": ["oTbmWlt2", "QGyxiutK"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 2}, {"id": "5WJqHcE5", "name": "Abstraction and scalability", "labels": [], "text_md": "Complexity increases when NSOs seek to mainstream data innovations beyond pilot projects run by a small team.  \"This makes enforcing ETL best practices, upholding data quality, and standardizing workflows increasingly challenging.\" \n\nIdentifying and automating common ETL patterns into standard workflows allows to leverage the power of abstraction in order to address scalability challenges.\n\n", "links": ["onHn6c4S"], "quotes": [], "sources": ["HKijdzxQ"], "n_links": 1}, {"id": "ilCtHTAx", "name": "Training for data innovation projects", "labels": [], "text_md": "Data innovation teams need to build a wide range of **data analysis and management** skills, including:\n- data engineering\n- data science\n- IT infrastructure engineering\n- statistical and econometric modeling\n- GIS analysis\n\nIt also requires building **\"soft\" skills**, such as project management, fund-raising, and communication.\n\n", "links": ["zGHMrgZh", "P43SdKCs", "JiEdFdtg", "Vmp2TR2i"], "quotes": [], "sources": [], "n_links": 4}, {"id": "P43SdKCs", "name": "Training materials for national staff", "labels": [], "text_md": "To enable national staff to reproduce the outputs of data innovation projects and to utilize innovative data sources, technologies and methods on a sustainable basis, it is crucial to develop training materials and knowledge resources tailored to their own needs and context.\n\n- In their own language\n- Applicable in their existing technological infrastructure\n\n", "links": ["ilCtHTAx", "JiEdFdtg", "Vmp2TR2i", "CNiPnq0T"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 4}, {"id": "JiEdFdtg", "name": "Engaging local universities and training institutes", "labels": [], "text_md": "To promote sustainability and national ownership, data innovation project teams need to partner with local universities or training institutes in order to train analysts at national statistical offices and other government agencies.\n\n", "links": ["QJsx3KmY", "ilCtHTAx", "P43SdKCs", "Vmp2TR2i"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 4}, {"id": "jwQ8qCBg", "name": "Loss of expertise through staff attrition", "labels": [], "text_md": "**Risk**: \n\nLoss of expertise through staff attrition or turnover\n\n**Mitigation**: \n\n- Maintain focus on institutional capacity rather than on individuals \n- Promote knowledge sharing and team collaboration (e.g., working in pairs and peer reviews)\n\n", "links": ["QRWAHOzF", "CNiPnq0T"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 2}, {"id": "HZvkseXI", "name": "Delivering methodology as a blackbox", "labels": [], "text_md": "Some aspects of data innovation projects are highly technical.  There is a risk of \"delivering methodology as a black box\", making it impossible for local teams to maintain and update the project results in the long run.\n\n", "links": ["zGHMrgZh"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 1}, {"id": "QRWAHOzF", "name": "Working in pairs to ensure sustainable skill building", "labels": [], "text_md": "In the face of high staff turnover rates, organizations face the challenge of retaining over the long term the skills acquired during training activities and hands-on implementation activities. \n\nTo address this challenge, a good practice is to ensure that in every activity related to the implementation of a project feature, at least two team members take the lead and are jointly responsible for the deliverable, and that they work via pairing and review each other's work,\n\n", "links": ["zGHMrgZh", "jwQ8qCBg"], "quotes": [], "sources": [], "n_links": 2}, {"id": "5u1sLb2p", "name": "Objectives of data innovation for Sustainable Development", "labels": [], "text_md": "- Data innovation projects should enable countries to *regularly* produce better, more timely and more disaggregated data to inform policies and decisions that contribute to achieving the 2030 Agenda for Sustainable Development\n- Measures of success: Data is available and openly accessible online to policy and decision makers in easy-to-use formats and presentations.\n  - Frequency (at least once a year)\n  - Time lag (less than 2 years)\n  - Geographic coverage (national coverage)\n  - Geographic disaggregation (at least 3rd level)\n  - Coverage of specific population groups (women, disabled, youth, elderly)\n\n", "links": ["QJsx3KmY", "ttc01lbK", "oTbmWlt2", "jt99xW61"], "quotes": [], "sources": [], "n_links": 4}, {"id": "vlQ3wkHh", "name": "Gaps in poverty data", "labels": [], "text_md": "Traditional poverty measures are generally available at low frequency intervals (e.g., every ten to five years) and only at highly aggregated levels of granularity\n\n>*As of \\[ \\], \\[  \\] countries have not poverty data at all for the period 2005-2019, and \\[   \\] have only one data point.   For half of in the global database, the most recent data point is for the year \\[  \\] or earlier. *\n\n\n", "links": ["jt99xW61"], "quotes": [], "sources": [], "n_links": 1}, {"id": "jt99xW61", "name": "Objectives of Data4Now country projects", "labels": [], "text_md": "Country projects supported as part of the Data4Now initiative aim to provide timely and disaggregated information needed by policy and decision makers to better design development strategies and policy programmes that \n\n  - reduce inequalities\n  - improve public service delivery\n  - ...\n\nThis includes producing nowcasting and small-area estimates on key topics such as poverty, food security, education, health, disaster-risk resilience, etc. \n\nIt also requires producing analytic data communication and visualization tools that enable users to explore patterns and correlations across different variables and over time and geography to obtain actionable insights. \n\nFor instance: \"How are drought patterns and commodity prices correlated with crop yields, poverty estimates, and population movements?\"\n\n", "links": ["vlQ3wkHh", "5u1sLb2p"], "quotes": [], "sources": [], "n_links": 2}, {"id": "1k64R7UM", "name": "Policy relevance of data innovation projects", "labels": [], "text_md": "To ensure broad support to data innovation projects, it is crucial to identify specific elements in the policy process where the outputs of the project will provide immediate value.\n\nIn order for the project to become part of the regular statistical production process, there most be a continuous search for new areas in the policy-making process that could benefit from it. \n\n", "links": ["CNiPnq0T"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 1}, {"id": "ttc01lbK", "name": "Defining data disaggregation priorities", "labels": [], "text_md": "The definition of national data priorities include the definition of priority dimensions for which disaggregated data needs to be available:\n\n- Key population groups (e.g., women, urban/rural population, indigenous groups, youth, elderly population, people living with disabilities, ...)\n- Required level of granularity in geographic disaggregation\n\n", "links": ["5u1sLb2p"], "quotes": [], "sources": [], "n_links": 1}, {"id": "QJsx3KmY", "name": "Data innovation road map", "labels": [], "text_md": "A road map of consisting of country-specific activities, intermediate outputs and expected outcomes\n\n**Pre-production:**\n\n1. Define **scope**\n1. Identify **key stakeholders**\n1. Build **suport** \n1. Reach out to **potential users**\n1. Secure **resources**\n1. Establish **project team**\n1. Procure/setup/configure the necessary **hardware and software** tools\n1. Secure **access to data** inputs\n1. Assess **quality of source data**\n1. Transform original source data into **analysis-ready datasets**\n1. Set up **data inputs clearinghouse**\n1. Provide **practical training**\n\n**Production:**\n\n1. Compute intermediate indicators to be used as (geospatial) covariates in statistical estimation models (e.g., distance to service-delivery points, distance to roads, elevation, ...)\n\n\n**Post-production:**\n\n1. Communicate project outputs to key audiences \n\n", "links": ["9h1AmchL", "2j4pK36q", "Cr014GcV", "Vmp2TR2i", "JiEdFdtg", "3c7dZcB6", "mmwn1oEU", "5u1sLb2p", "1P7GAwhy", "U3iX23IM", "CvXRU020", "XVq7u8bY", "yHy01yYb", "VG23wXyp", "QZ4e6WSS"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 15}, {"id": "XVq7u8bY", "name": "Poverty map production: basic steps", "labels": [], "text_md": "Estimation of small-area poverty maps usually follows methodology developed by the World Bank over more than 20 years, combining census data with household survey data. This methodology usually includes the following general steps:\n\n1. Verify quality and comparability of Household survey data and census data\n2. Verify quality of additional geospatial co-variates\n3. Estimate a model of household consumption, based on data sample from household survey (using only variables that are available in both survey and census data) and geospatial co-variates.\n4. Apply estimated parameters to census data and geospatial co-variates in order to estimate consumption per capita for all households in the census\n5. Apply appropriate poverty lines to estimate poverty rates at various levels of aggregation\n6. Build confidence intervals using standard errors\n7. Use GIS to produce visualizations of the results\n\n\n", "links": ["QJsx3KmY", "nqqQlCkb"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 2}, {"id": "nqqQlCkb", "name": "Poverty maps production: data sources", "labels": [], "text_md": "The production of small-area poverty estimates usually relies on the following two major data sources of household welfare:\n\n1. Detailed household surveys which collect a measure of welfare (typically consumption per capita)\n2. A national census or large national survey that includes a significant share of the country's population\n\nOther data sources that may be used to approximate individual welfare (in approximately real time):\n\n- Individual consumption of mobile phone services\n- Measures of mobility (e.g., derived from mobile phone records)\n- Social network metrics (e.g., derived from social media or mobile phone records)\n- Financial transactions (e.g., derived from mobile phone or credit card records)\n\n", "links": ["exFglBfe", "njfyBuRv", "RHCUOmoR", "XVq7u8bY", "vWWASKo8"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 5}, {"id": "vWWASKo8", "name": "Additional geo-referenced information used in poverty estimation", "labels": [], "text_md": "- Points of service delivery (e.g., schools, health centers, boreholes...) and their attributes (e.g., number of beds in hospitals; number of health personnel)\n- Networks of infrastructure (e.g., roads, electricity, water...) and their attributes (e.g., condition/quality of roads)\n- Natural features (e.g., elevation, agroclimatic characteristics...)\n\n", "links": ["nqqQlCkb"], "quotes": [], "sources": [], "n_links": 1}, {"id": "exFglBfe", "name": "Challenges in using mobile phone records", "labels": [], "text_md": "- Mobile phone data are typically biased and not representative of the entire population of interest, due to factors such as unequal phone penetration and differences in market share by various carriers\n- Working with mobile phone records requires additional privacy protection measures. \n\n", "links": ["nqqQlCkb"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 1}, {"id": "njfyBuRv", "name": "Challenges in household survey data", "labels": [], "text_md": "Household surveys provide rich information on the living standards and other characteristics of a sample of households.  However, their sample size is typically not large enough to obtain reliable estimates of poverty levels below the first sub-national administrative unit.\n\n", "links": ["nqqQlCkb"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 1}, {"id": "2j4pK36q", "name": "Key stakeholders in data innovation projects", "labels": [], "text_md": "In every data innovation project, it is very important to identify from the beginning a broad range of actual and potential stakeholders who may become involved in various phases of the project. This includes:\n\n- **Data providers** (line ministries, land administration, mobile phone companies, industry regulators, business associations, local governments, civil society organizations, space agencies, tech companies...)\n- **Technology providers** (e.g., national data centers, intl. organizations, private sector)\n- **Knowledge and expertise providers** (e.g., international organizations, research institutes, universities...)\n- **Funding providers** (e.g., ministry of planning/finance, intl. donors)\n- **Data users** (e.g., line ministries, parliament, local governments, international organizations, civil society organizations, intl. donors)\n\nIt is also crucial to establish from the beginning both institutional and personal links with these stakeholders, and to involve them early on in the planning and execution of project activities.\n\n", "links": ["QJsx3KmY", "4RDMe98t", "38O0h16q"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 3}, {"id": "VG23wXyp", "name": "Hardware and software tools", "labels": [], "text_md": "Data innovation projects require a number of hardware and software tools\n\n- Statistical software packages and libraries\n- Database management tools/environments\n- Data visualization tools\n- GIS tools\n\n", "links": ["QJsx3KmY", "hp8Foh4V"], "quotes": [], "sources": [], "n_links": 2}, {"id": "mmwn1oEU", "name": "Establishing a national project team", "labels": [], "text_md": "Each project requires dedicated personal, both from the NSO and from other participating agencies, to carry out the work at the country level.  The national project team should consist of:\n\n- A national project coordinator (bridge between technical team at NSO and other stakeholders)\n- Two statisticians (closely familiar with source data and statistical analysis prcesses)\n- One econometricians (with expertise in nocasting and/or small area estimation techniques)\n- One GIS expert (with expertise in GIS analysis and map visualization tools)\n- One IT focal point (with admin rights and familiar with data security protocols)\n- Two policy experts\n\n", "links": ["QJsx3KmY", "duUZSb3j", "Vk1c3Bjw"], "quotes": [], "sources": [], "n_links": 3}, {"id": "duUZSb3j", "name": "Collaborative data innovation projects", "labels": [], "text_md": "Data innovation projects that seek to produce nowcasting or small-area estimates require the collaboration of multiple government agencies and partners, with multi-stakeholder, multi-disciplinary teams working together to process ans analyze different data inputs.\n\nIt is therefore crucial to establish and strengthen collaboration across different organizations towards producing a common output and achieving a shared outcome.\n\n", "links": ["mmwn1oEU"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 1}, {"id": "Vk1c3Bjw", "name": "Allocation of staff to data innovation projects", "labels": [], "text_md": "Risk: Lack of time availability of skilled technical staff\n\nMitigation: To be successful, any data innovation project must have dedicated staff, who must be freed up from other duties to participate in it (trainings, data analysis, coordination) \n\n", "links": ["mmwn1oEU", "hp8Foh4V"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 2}, {"id": "1P7GAwhy", "name": "Sustainable access to source data", "labels": [], "text_md": "To be sustainable, producers of statistics need to have the capacity to regularly access to the necessary input data from external sources.\n\nThis requires:\n- Effective legal data exchange arrangements \n- Adequate incentives and business models\n- Appropriate technical data exchange standards and protocols\n- Good data exchange infrastructure, including connectivity and bandwidth.\n\n", "links": ["QJsx3KmY", "QGyxiutK"], "quotes": [], "sources": [], "n_links": 2}, {"id": "lEHhU8Ma", "name": "ETL - Making data analysis-ready", "labels": [], "text_md": "The 'extract-tranform-load' (ETL) pattern is how most data pipelines are designed to transform raw data into analysis-ready data. this includes:\n\n1. Extracting input data from their original sources\n2. Transforming them it into usable data structures through transcoding, filtering, joining, and aggregation operations\n3. Uploading the transformed data onto a controlled data management environment (such as a data warehouse)\n\n\n", "links": ["2GTwGKsm", "2fx14QVS", "UHxZBMU2", "Vmp2TR2i", "FOPuLnHI"], "quotes": [], "sources": ["4z5iFWrh"], "n_links": 5}, {"id": "FOPuLnHI", "name": "ETL principles", "labels": [], "text_md": "Principles of good ETL pipelines:\n\n- Partition data tables\n- Load data incrementally\n- Use imutable data tables - so queries return the same result when run against the same business logic and time range\n- Parameterize backfilling logic\n- Run early and frequent data checks: Write data into a staging table first, validate data quality, and only then push to final production table\n- Build alerts and monitoring system\n\n\n", "links": ["lEHhU8Ma", "5W8MgJOp", "Jwlw5emQ"], "quotes": [], "sources": ["oIarYHfE"], "n_links": 3}, {"id": "CvXRU020", "name": "Source data catalog", "labels": [], "text_md": "Build a hub providing access to **analysis-ready, geo-referenced data inputs** from multiple sources, organized according to **fundamental geospatial data themes** \n\nA lot of work may be required to \"condition\" the different data inputs in order to make them ready for use and analysis, including the adoption of data **interoperability standards and best practices** across different data sources and systems.  \n\n", "links": ["QJsx3KmY", "bR2Woaf4", "Cr014GcV", "cTjLfkWN"], "quotes": [], "sources": [], "n_links": 4}, {"id": "bR2Woaf4", "name": "Types of source data required for nowcasting", "labels": [], "text_md": "Nowcasting is about producing \"near real-time\" estimates.  This means being able to project in over time the values of variables measured in the past.\n\nThis in turn requires to leverage any \"panel components\" in input data form household surveys, administrative records, etc., which track the same individuals, households or statistical units with repeated measurement of the same variable(s) at different moments in time.\n\n", "links": ["CvXRU020", "Lr60zbkO"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 2}, {"id": "Lr60zbkO", "name": "Understanding multiple sources of data", "labels": [], "text_md": "No single individual (or organization) is ever familiar with all the attributes and caveats of all the data inputs that are required in a data innovation project.   Therefore, it is crucial to involve from the beginning all relevant experts who have helped produced various data inputs.\n\n", "links": ["yHy01yYb", "bR2Woaf4", "cTjLfkWN"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 3}, {"id": "cTjLfkWN", "name": "How to improve interoperability across data sources", "labels": [], "text_md": "To make various data sources ready-to-use, it is necessary to transform them to ensure they are interoperable. This includes:\n\n- Use of canonical data models\n- Geo-reference all data inputs using common boundaries and use consistent location-identification codes \n- Use common vocabularies, classifications and code lists\n- Develop of standardized API documentation\n\n\n", "links": ["pXxz1MHR", "yHy01yYb", "6WFYziDD", "CvXRU020", "Lr60zbkO"], "quotes": [], "sources": [], "n_links": 5}, {"id": "yHy01yYb", "name": "Assessing quality of source data", "labels": [], "text_md": "- Verify quality of individual data sources\n  - Outlier detection\n  - Completeness of data / missing observations\n  - Sample bias / representativity\n  - Interoperability\n  - Internal consistency\n  - Completeness and clarity of reference metadata\n- Verify comparability / consistency across data sources\n\n", "links": ["QJsx3KmY", "9h1AmchL", "hp8Foh4V", "6WFYziDD", "cTjLfkWN", "Lr60zbkO"], "quotes": [], "sources": [], "n_links": 6}, {"id": "6WFYziDD", "name": "Comparability across data sources", "labels": [], "text_md": "The comparability of variables measured across different data sources is a key data quality issue.  \n\nChanges over time that may adversely impact comparability of variables across different data sets include:\n\n- Changes in the definition and coverage of reference geographic areas (e.g., creation or re-drawing of boundaries of new administrative units)\n- Changes in statistical classifications\n- Changes in sampling methodology\n- Changes in definition of reference time periods (e.g., calendar vs. fiscal year)\n- Changes in survey questions or measurement instruments\n\n", "links": ["yHy01yYb", "cTjLfkWN"], "quotes": [], "sources": [], "n_links": 2}, {"id": "9h1AmchL", "name": "Establishing trust in results of data innovation projects", "labels": [], "text_md": "It is crucial to establish trust in the results of data innovation projects, particularly from key users such as policy and decision makers.\n\nThe quality of estimation results \"is only as good as the quality of the input data and the methodologies employed.\"  Therefore, the reliability of the sources and methods involved in data innovation projects is central to their widespread acceptance and use. \n\nThis highlights the importance of **transparent and participatory validation**:\n\n- Validate quality of data inputs\n- Validate methodology\n- Ensure that data production process are reproducible by independent reviewers\n- Check for internal and external consistency of results\n- Compare pre-existing users' perceptions with project results\n\n\n", "links": ["QJsx3KmY", "J7uVnj8B", "rKAEb7YK", "3c7dZcB6", "1cHc8MiO", "yHy01yYb"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 6}, {"id": "3c7dZcB6", "name": "Communicating results of data innovation projects", "labels": [], "text_md": "**Risk:**\n\n- Outputs from data innovation projects do not reach their intended users, and remain unused by policy and decision makers\n- Key insights and caveats of project results are not presented in formats that are easy to understand by different types of technical and non-technical users \n- Potential users are not aware of project outputs and/or their value to inform policy and decision making\n\n**Mitigation:**\n\n- Develop a results communication strategy aimed to maximize the reach of the outputs and their impact. This strategy may include, among other things:\n  - A **social media campaign** to highlight main results and outputs, and direct user to data and resources to understand the underlying methodologies. \n  - **Online dissemination of results** through the official data dissemination platforms of the NSO and participating government agencies, including: \n    - Downloadable **datasets**\n    - Online **maps and visualizations**\n    - Data stories / **narratives** that put data outputs in context and make them easier to understand for policy and decision makers\n  - Production and distribution of project **reports** in multiple formats\n  - User outreach **events**\n\n", "links": ["QJsx3KmY", "9h1AmchL", "tZWRLOUI", "JExDAHlM", "wFd1FvbC", "etUj8mX6"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 6}, {"id": "tZWRLOUI", "name": "Elements of a results communication strategy", "labels": [], "text_md": "- Identify potential **users** and their needs\n- Determine the **types of information products / formats / media** that are best suited to the needs of these users\n- Identify / develop internal and external **dissemination outlets**\n- Develop a clear **policy on access** to the results and the underlying data inputs (data licences)\n- Develop **documentation** to explain the methodology to users and to provide guidance on the appropriate interpretation of the results\n- Make all results available in all the **languages** in which the government works\n\n", "links": ["3c7dZcB6"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 1}, {"id": "rKAEb7YK", "name": "Official statistics is there for the truth", "labels": [], "text_md": "(paraphrasing Alexander von Humboldt):\n\nOfficial statistics is only there for the truth, and truth is always a public matter.  Everything within official statistics aims at some kind of publication.  Every statistical publication is a public claim on truth.\n\n", "links": ["9h1AmchL"], "quotes": ["falIut3E"], "sources": [], "n_links": 1}, {"id": "Cr014GcV", "name": "Fundamental Geospatial Data Themes", "labels": [], "text_md": "The 14 Global Fundamental Geospatial Data Themes adopted by UNGGIM at its seventh session under decision 7/104 provide a \"taxonomy\" of the geospatial data assets that are needed to enable \"the measurement, monitoring and management of sustainable development in a consistent way over time and to facilitate evidence-based decision making and policy-making.\" \n\nThey can be used to facilitate global geospatial information management and the implementation of the integrated geospatial information framework.\n\n1. Global geodetic reference frame* \n2. Addresses\n3. Buildings and settlements\n4. Elevation and depth\n5. Functional areas\n6. Geographic names\n7. Geology and soils\n8. Land cover and land use\n9. Land parcels\n10. Orthoimagery\n11. Physical infrastructure\n12. Population distribution (including population characteristics)\n13. Transport networks\n14. Water\n15. Economy*\n\n(*) Additional theme not included in the 14 GFGDT\n\n\n", "links": ["QJsx3KmY", "CvXRU020", "RHCUOmoR"], "quotes": [], "sources": ["ewmJWk6r"], "n_links": 3}, {"id": "RHCUOmoR", "name": "Use of EO in poverty mapping", "labels": [], "text_md": "Poverty mapping projects typically use geospatial datasets derived from high-resolution EO imagery, including:\n\n- Land cover\n- Land use\n- Objects (cars, buildings, ...)\n- Night-time lights\n- Road networks\n- ...\n\n", "links": ["nqqQlCkb", "Cr014GcV"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 2}, {"id": "pXxz1MHR", "name": "Geo-referencing", "labels": [], "text_md": "Geo-referencing makes it relatively easy to bring together, overlay and analyze information from multiple sources based on different units of analysis. \n\n", "links": ["cTjLfkWN"], "quotes": [], "sources": ["UCi2QXBJ"], "n_links": 1}, {"id": "1cHc8MiO", "name": "Reproducibility of processes", "labels": [], "text_md": "The ability to reproduce processes is crucial to generate trust in their outputs.\n\nReproducibility requires immutable data and versioned logic (adoption of functional programming).\n\n", "links": ["9h1AmchL", "v0j3xMCw", "vLPsC8l0"], "quotes": [], "sources": ["fj461XsQ"], "n_links": 3}, {"id": "vLPsC8l0", "name": "Pure tasks", "labels": [], "text_md": "- **Pure tasks** produce the same result every time they are run.\n- **Overwrite approach**: \"Re-executing a pure task with the same input parameters should overwrite any previous output that could have been left out from a previous run of the same task.\"\n- Tasks can become \"purified\" by breaking them down into smaller tasks, each of which targets a single output. \n\n", "links": ["1cHc8MiO", "JExDAHlM"], "quotes": [], "sources": ["fj461XsQ"], "n_links": 2}, {"id": "v0j3xMCw", "name": "Functional programming", "labels": [], "text_md": "(https://en.wikipedia.org/wiki/Functional_programming)\n\n\n- A programming paradigm \"that treats computation as the evaluation of mathematical functions\", avoiding \"changing state and mutable data\". \n- The output of a function depends only on the arguments passed to it\n- This approach makes it easier to understand the code and to predict outputs\n- Functions can be written and tested in isolation \\(without having to understand external context\\)\n- Through immutable data and versioned logic, functional programming allows to **insulate logic changes from data changes**, thus enhancing **reproducibility of results** \n \n\n\n\n", "links": ["1cHc8MiO", "YOp0ve5T", "3BmAWMzw"], "quotes": [], "sources": ["fj461XsQ"], "n_links": 3}, {"id": "Jwlw5emQ", "name": "A persistent and immutable staging area", "labels": [], "text_md": "By accumulating and persisting all source data in a stating area (keeping it forever unchanged) one can have shorter retention policy on derived tables, \"knowing that it\u2019s possible to backfill historical data at will.\"\n\n", "links": ["FOPuLnHI"], "quotes": [], "sources": ["fj461XsQ"], "n_links": 1}, {"id": "YOp0ve5T", "name": "Changing data warehouse logic over time", "labels": [], "text_md": "Changes in data warehouse logic over time should be either \n- expressed with data (in the form of \"parameter tables\") using effective dates\n- captured in source control, so they can applied conditionally, allowing to build the full state of the data warehouse throughout all time periods, or\n\nBeauchemin (2018) illustrates this with the example of introducing a change in the way taxes are calculated in year t.  If a users \"back-fills\" data for year t-1, the change in tax calculation method should not be applied. \n\n", "links": ["v0j3xMCw", "3BmAWMzw"], "quotes": [], "sources": ["fj461XsQ"], "n_links": 2}, {"id": "3BmAWMzw", "name": "Changing data warehouse dimensions over time", "labels": [], "text_md": "In order to model changing dimensions in functional data warehouses without mutating data, one could use a collection of \"dimension snapshots\", whit each snapshot containing the full dimensions available at a specific point of time.\n\n \n\n\n", "links": ["YOp0ve5T", "v0j3xMCw", "6OomPFuc"], "quotes": [], "sources": ["fj461XsQ"], "n_links": 3}, {"id": "2GTwGKsm", "name": "ETL Frameworks", "labels": [], "text_md": "Developing and implementing ETL (extract-tranform-load) processes is \"time-consuming, brittle, and often unrewarding\" (Beauchemin, 2018)\n\nThe data flows of real-life statistical production processes can be very complex, and ETL frameworks help address common problems in building ETL pipelines:\n\n- Documentation - Succinctly describe the data flow\n- Monitoring - Track the progress of long running processes and alert when errors arise\n- Backfilling - Ability to re-process historical data\n\n", "links": ["lEHhU8Ma", "2fx14QVS"], "quotes": [], "sources": ["fj461XsQ,", "4z5iFWrh"], "n_links": 2}, {"id": "2fx14QVS", "name": "Representing ETL jobs as Directed Acyclic Graphs (DAG)", "labels": [], "text_md": "It is often useful to visualize complex ETL data flows using a directed acyclic graph, where each node corresponds to a task (which only needs to be performed once), and arrows represent dependencies between tasks. \n\n", "links": ["2GTwGKsm", "lEHhU8Ma"], "quotes": [], "sources": ["oIarYHfE"], "n_links": 2}]